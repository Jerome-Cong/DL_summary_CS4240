{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Part 1",
      "metadata": {
        "tags": [],
        "cell_id": "00000-68c1969d-f594-4b52-97f4-009f8a109655",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Lecture 1\n**Multi-layered perceptron** (Deep Feed forward network):\n- Depth: input (1), hidden layer(s), output (1)\n    - Ex: 3\n- (learnable) parameters: weight & bias\n    - Ex: 9 (arrows & activation functions)\n- Update weights by minimizing a cost/loss/error-function\n    - MSE, CE\n    - Ex: reduce by moving in opposite sign of derivative (Gradient Descent)\n- Gradient is vector of all partial derivatives -> all weights\n    - Mostly done in batches, since huge datasets a step can take too long\n    - Ex: SGD is approximation of the gradient from (small) number of samples\n        - smaller batches: more noise\n        - SGD is more computationally efficient\n- Decision boundary might not be linearly separable, thus make it non-linear:\n    - Generic kernel function\n    - Designing feature extractors\n    - Learn it ( add knowledge to restrict 1, more flexible than 2)\n    - Use non-linear functions\n        - ReLU, Sigmoid, Max, ...\n\n<img src=\"/image/Multilayeredperceptron.png\" height=\"250\" />",
      "metadata": {
        "tags": [],
        "cell_id": "00001-79e48913-cfec-461b-b791-fec9add38b25",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Assignment 1: Forward pass\nIn the forward pass it only computes the **loss and activations**.\n\n*in_features = 7, out_features = 5*\n\n<img src=\"/image/fully_connected_layer.png\" height=\"250\" />\n\n- **in** = (n_samples, in_features)\n- Linear (fully connected) layer = (in_features, out_features)\n    - Weight = (in_features, out_features)\n    - Bias = (out_features)\n- **out** = (n_samples, out_features)\n\nNon-linear Functions:\n- ReLU(x) = max(0, x) \n    - [0, $$+\\infty$$)\n- Sigmoid(x) = $$\\sigma$$(x) = $$\\frac{1}{1 + exp(-x)}$$ \n    - \\[0, 1]\n\nLoss Functions:\n- $$\\text{MSE}(\\hat{y},y)= \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}-y)^2 $$\n    - unbounded and minimize error\n    - used for regression",
      "metadata": {
        "tags": [],
        "cell_id": "00001-4d99f4ed-5c1a-4db7-8997-884985024f67",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-b908d030-f161-4643-8bca-d8f57f3bd610",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6672f62e",
        "execution_millis": 4,
        "execution_start": 1617986392938,
        "deepnote_cell_type": "code"
      },
      "source": "import torch\nimport torch.nn as nn\nfrom torchinfo import summary\n\nnr_samples = 3\nin_features = 7\nout_features = 5 # Also bias size\nbias=False\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(in_features, out_features, bias=bias)\n\n    def forward(self, x):\n        return self.fc1(x)\n\n\nmodel_ouput = summary(\n    Net(), \n    (in_features,),\n    verbose=2,\n    col_width=16,\n    col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"])",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "========================================================================================================\nLayer (type:depth-idx)                   Kernel Shape     Input Shape      Output Shape     Param #\n========================================================================================================\n├─Linear: 1-1                            [7, 5]           [7]              [5]              35\n========================================================================================================\nTotal params: 35\nTrainable params: 35\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n========================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.00\n========================================================================================================\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Another example:\n$$$\nw^T\\text{max}(0, W^Tx+c) + b\n$$$",
      "metadata": {
        "tags": [],
        "cell_id": "00005-982cbca4-cc38-40f5-b787-79daba4f2f4c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nfrom torchinfo import summary\n\nnr_samples = 3\nin_features = 3\nhidden_size = 4\nout_features = 1\nbias=True\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(in_features, hidden_size, bias=bias)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(hidden_size, out_features, bias=bias)\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))\n\n\nmodel_ouput = summary(\n    Net(), \n    (in_features,),\n    verbose=2,\n    col_width=16,\n    col_names=[\"kernel_size\", \"input_size\", \"output_size\", \"num_params\"])",
      "metadata": {
        "tags": [],
        "cell_id": "00004-6168b55d-6512-41a7-b83c-9b05f163bad5",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "47a24486",
        "execution_millis": 16,
        "execution_start": 1618214475354,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "========================================================================================================\nLayer (type:depth-idx)                   Kernel Shape     Input Shape      Output Shape     Param #\n========================================================================================================\n├─Linear: 1-1                            [3, 4]           [3]              [4]              16\n├─ReLU: 1-2                              --               [4]              [4]              --\n├─Linear: 1-3                            [4, 1]           [4]              [1]              5\n========================================================================================================\nTotal params: 21\nTrainable params: 21\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n========================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.00\n========================================================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=de0be7a9-29e1-4ab6-9ce7-607fa646094e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "036f984d-db2f-43ee-9d16-e1fd7b977911",
    "deepnote_execution_queue": []
  }
}
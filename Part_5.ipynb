{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Part 5",
      "metadata": {
        "tags": [],
        "cell_id": "00000-5f5f69a4-ddae-4f0a-ba4f-ba174dc011a3",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Lecture 5\n**Learning rate** arguably most important parameter to tune\n- Too high? Never find a good instantiation\n- Too low? Take a very long time to find a good instantiation\n\nDo LR Decay over time, to keep making smaller steps\n\n**Batch normalization**:\nSpeed up convergence speed by computing the norm by using a weighted average for the mean and variance. (Some features are not equally scaled)\n\n**Feature normalization**:\nApply it to all layers if it should could for whole deep neural net.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-9c30be82-c5e5-4adb-9127-2e45f8ce2959",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Assignment 5: Optimization\n\n**EWMA**\n- Exponentially weighted moving average\n<!-- - $$S_t=\\rho S_{t-1} + (1-\\rho)y_t$$\n    - $$\\rho$$ strength of smoothing (how much determined by average and current value) -->\n- Smooth out noisy data\n- Memory efficient & flexible (only store previously calculated avg)\n    - No need for a sliding window average (which is more computationaly expensive)\n- Form basis of Adam, Momentum, RMSProp\n\n<img src=\"./image/EWMA_visualized.png\" height=\"300\" />\n\n_Border effect_: larger $\\rho$, later it catches up (unknown what happened before time):\n- At beginning values are too close to zero (which bias correction tries to fix)\n- **Red**: without bias correction\n- **Green**: with bias correction (Starting point matches up better)\n- Higher $\\rho$, leads to a **smoother line**.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-e0504dc4-7eb5-4cc8-840a-dc8a9f2b30dc",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Stochastic Gradient Descent**\n- Follows the gradient\n- Requires carefully tuning LR (prevent overshooting and slow convergence)\n- Zigzag shape\n    - Gradient is computed on random samples\n- More computationally efficient than \"gradient descent\"",
      "metadata": {
        "tags": [],
        "cell_id": "00002-fa1af89a-bc2f-4d18-ac62-433368b06af7",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Momentum**\n- On average in the good direction\n- EWMA applied to Gradient Descent, **update gradient directly**\n- Smoothen updates; helps overshooting minimum (too high LR), smoothing the **average of noisy gradients**.\n- Often implemented without bias correction.\n- Momentum: $$v_i=\\rho v_{i-1}+(1-\\rho)\\nabla_{\\theta}$$\n    - $$\\theta^{\\prime}=\\theta-\\epsilon v_i$$\n",
      "metadata": {
        "tags": [],
        "cell_id": "00002-9bb390a1-9a98-4839-9e45-a704f3566138",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**RMSProp**\n- Variance in the wrong direction is high\n- EWMA applied to Gradient Descent, **update scale of LR**\n- Take larger steps in beginning and smaller towards the end. Smooths the **zero-centered variance of noisy gradients**.\n- Add small epsilon to prevent dividing by zero.\n- Often implemented without bias correction.\n- RMSProp: $$r_i=\\rho r_{i-1}+(1-\\rho)\\nabla^2_{\\theta}$$\n    - $$\\theta^{\\prime}=\\theta-\\epsilon \\frac{\\nabla_\\theta}{\\sqrt{r_i+\\delta}}$$",
      "metadata": {
        "tags": [],
        "cell_id": "00003-35871a60-be6d-4804-ba16-b49b8f48336e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Adam**\n- Combine Momentum + RMSProp\n    - gradients: average noisy + zero-centered variance\n- Often implemented **with** bias correction.\n- $$v_i=\\rho_1 v_{i-1}+(1-\\rho_1)\\nabla_{\\theta}$$\n    - $$\\hat{v_i}=\\frac{v_i}{1-\\rho^i_1}$$\n    - $$r_i=\\rho_2 r_{i-1}+(1-\\rho_2)\\nabla^2_{\\theta}$$\n    - $$\\hat{r_i}=\\frac{r_i}{1-\\rho^i_2}$$\n    - $$\\theta^{\\prime}=\\theta-\\epsilon \\frac{\\hat{v_i}}{\\sqrt{\\hat{r_i}+\\delta}}$$",
      "metadata": {
        "tags": [],
        "cell_id": "00004-a9543909-0f13-4124-a682-cb33bfca0abd",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Comparison\n- **Red**: SGD\n- **Blue**: Momentum\n- **Yellow**: RMSProp\n- **Green**: Adam\n\n<img src=\"./image/Optimization_difference.png\" height=\"300\" />",
      "metadata": {
        "tags": [],
        "cell_id": "00006-dc4027fc-78e7-4268-8bd4-44b0d0514ab9",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=de0be7a9-29e1-4ab6-9ce7-607fa646094e' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_notebook_id": "058927cd-7146-4ee6-982c-fcefd35e6efd",
    "deepnote_execution_queue": []
  }
}